model_class: "blip2"
model_shorthand: "instructblip_flant5xl"
class_name: "instructblip"
model_display_name: "InstructBLIP-FlanT5XL"
pt_model_load:
  name: "blip2_t5_instruct"
  type: "flant5xl"

  model_config:
    arch: pretrain_flant5xl
    load_finetuned: False

    pretrained: "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/InstructBLIP/instruct_blip_flanxl_trimmed.pth"
    finetuned: ""

    # vit encoder
    image_size: 224
    img_size: 224
    drop_path_rate: 0
    use_grad_checkpoint: False
    vit_precision: "fp16"
    freeze_vit: True
    max_txt_len: 300

    # Q-Former
    num_query_token: 32

    # T5
    t5_model: "google/flan-t5-xl"

    # generation configs
    prompt: ""

  preprocess_config:
      vis_processor:
          train:
            name: "blip_image_train"
            image_size: 224
          eval:
            name: "blip_image_eval"
            image_size: 224
      text_processor:
          train:
            name: "blip_caption"
            max_words: 300
          eval:
            name: "blip_caption"
            max_words: 300