{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7cbf88-9314-44ca-a4c1-21105fa213b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tejass/.conda/envs/recoverr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pdb\n",
    "import yaml\n",
    "from typing import List, Union, Dict, Tuple\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "from data.aokvqa import AOKVQADataset\n",
    "from utils.okvqa_utils import postprocess_ok_vqa_generation, lemmatize\n",
    "from utils.openai_utils import openai_caller\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "        level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358e69e6-e19f-41a6-aefb-0dd3b1cc5997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/14/2024 00:11:44 - INFO - data.aokvqa - Loaded A-OKVQA train dataset with 17056 examples!\n",
      "01/14/2024 00:11:44 - WARNING - data.aokvqa - Vision/text processors not set!\n"
     ]
    }
   ],
   "source": [
    "dataset = AOKVQADataset('train')\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928b5e6e-1e4d-4da5-a121-4abb48771aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tejass/.conda/envs/recoverr/lib/python3.10/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "01/14/2024 00:12:01 - INFO - root - freeze vision encoder\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.41it/s]\n",
      "01/14/2024 00:12:29 - INFO - root - load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/InstructBLIP/instruct_blip_flanxl_trimmed.pth\n",
      "01/14/2024 00:12:32 - INFO - models.vlm - Loaded BLIP (model=InstructBLIP-FlanT5XL)!\n",
      "01/14/2024 00:12:32 - INFO - models.vlm - Model size: 4.02B parameters (0.19B trainable), 8.42GB in memory\n",
      "01/14/2024 00:12:32 - INFO - models.vlm - ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models.llm import LLM_CLASS_MAP\n",
    "from models.vlm import VLM_CLASS_MAP\n",
    "from models.qgen import QGEN_CLASS_MAP\n",
    "\n",
    "config_file = '/net/nfs.cirrascale/mosaic/tejass/code/ReCoVERR/configs/recoverr_configs/aokvqa/chatgpt_qgen-flant5xl_llm-instructblipft5xl_vlm.yaml'\n",
    "\n",
    "# Create agent and environment\n",
    "config = yaml.safe_load(open(config_file))\n",
    "\n",
    "# Load VLM\n",
    "vlm_class = config['vlm']['class_name']\n",
    "vlm_model_class = VLM_CLASS_MAP[vlm_class]\n",
    "vlm_config = yaml.safe_load(open(config['vlm']['model_config_path']))\n",
    "vlm_model = vlm_model_class(vlm_config, device)\n",
    "vlm_model.set_vqa_inference_params(config['vlm']['vqa_inference_params'])\n",
    "vlm_model.set_caption_inference_params(config['vlm']['caption_inference_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62bb710-57ec-455f-a1e6-76c5a4d44c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████▋                                                                                 | 4675/17056 [24:50<1:02:15,  3.31it/s]"
     ]
    }
   ],
   "source": [
    "yn_outputs_file = '/net/nfs.cirrascale/mosaic/tejass/experiments/vl_calibration/uncalibrated_yn_probs/instructblipflant5xl-aokvqa_train_direct_answer.json'\n",
    "directvqa_rollouts = json.load(open('/net/nfs.cirrascale/mosaic/tejass/experiments/recoverr/aokvqa_direct_answer/train_outputs/instructblipflant5xl_direct_vqa-1rollouts-17056examples.json'))\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, d in enumerate(tqdm(dataset)):\n",
    "    question = d['question']\n",
    "    image = d['raw_image']\n",
    "    qid = d['qid']\n",
    "    answer, logprobs_dict = vlm_model.ask(image, question)\n",
    "    r = directvqa_rollouts[qid][0]\n",
    "    result = {\n",
    "        \"qid\": qid,\n",
    "        \"image_id\": r['image_id'],\n",
    "        \"question\": r['vqa_question'],\n",
    "        \"answer\": answer,\n",
    "        \"yn_logits\": logprobs_dict['yn_logits'], \n",
    "        \"lave_score\": r['lave_score'], \n",
    "    }\n",
    "    results.append(result)\n",
    "    if i == 5000:\n",
    "        break\n",
    "\n",
    "json.dump(results, open(yn_outputs_file, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0dcb82-d7c0-4ffb-b039-efc7156431ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-recoverr] *",
   "language": "python",
   "name": "conda-env-.conda-recoverr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
