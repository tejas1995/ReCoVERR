model_class: "blip"
model_shorthand: "blip2_flant5xl"
model_display_name: "BLIP2-FlanT5XL"
pt_model_load:
  name: "blip2_t5"
  type: "pretrain_flant5xl"

  model_config:
    arch: pretrain_flant5xl
    load_finetuned: False

    pretrained: "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth"
    finetuned: ""

    # vit encoder
    image_size: 224
    img_size: 224
    drop_path_rate: 0
    use_grad_checkpoint: False
    vit_precision: "fp16"
    freeze_vit: True
    max_txt_len: 300

    # Q-Former
    num_query_token: 32

    # T5
    t5_model: "google/flan-t5-xl"

    # generation configs
    prompt: ""

  preprocess_config:
      vis_processor:
          train:
            name: "blip_image_train"
            image_size: 224
          eval:
            name: "blip_image_eval"
            image_size: 224
      text_processor:
          train:
            name: "blip_caption"
            max_words: 300
          eval:
            name: "blip_caption"
            max_words: 300
vqa_inference_params:
  num_beams: 5
  length_penalty: -1.0
  return_dict_in_generate: True
  output_scores: True